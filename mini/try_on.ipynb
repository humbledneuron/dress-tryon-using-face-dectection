{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3.3 #left over will not be shown in camera and also the total transparent\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the maximum scale factor to enlarge the dress as much as possible while fitting within the detected face\n",
    "    scale_factor = max(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 1.5, fy=scale_factor * 1.5)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(h * 0.8)  # Adjust the value to position the dress below the neck\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 250\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest for the dress overlay\n",
    "    dress_roi_y_start = max(dress_y, 0)\n",
    "    dress_roi_y_end = min(dress_y_end, frame.shape[0])\n",
    "    dress_roi_x_start = max(dress_x, 0)\n",
    "    dress_roi_x_end = min(dress_x_end, frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest in the dress image\n",
    "    dress_img_roi_y_start = dress_roi_y_start - dress_y\n",
    "    dress_img_roi_y_end = dress_img_roi_y_start + (dress_roi_y_end - dress_roi_y_start)\n",
    "    dress_img_roi_x_start = dress_roi_x_start - dress_x\n",
    "    dress_img_roi_x_end = dress_img_roi_x_start + (dress_roi_x_end - dress_roi_x_start)\n",
    "\n",
    "    # Extract the dress overlay and mask within the region of interest\n",
    "    dress_overlay = resized_dress[dress_img_roi_y_start:dress_img_roi_y_end, dress_img_roi_x_start:dress_img_roi_x_end]\n",
    "    dress_mask = dress_overlay[:, :, -1] / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Apply the dress overlay to the frame within the region of interest\n",
    "    frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3] = (\n",
    "            dress_mask[:, :, np.newaxis] * dress_overlay[:, :, :3] +\n",
    "            inv_dress_mask[:, :, np.newaxis] * frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def process_and_save_output(frame, dress_index, detections, x, y, w, h):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        dress_img = dress_images[dress_index]\n",
    "        apply_dress(frame_copy, dress_img, x, y, w, h)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "        #os.system(f'start {output_path}') #if want pop up\n",
    "\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    current_dress_index = 0\n",
    "    processed_all_dresses = False\n",
    "\n",
    "    while cam.isOpened() and not processed_all_dresses:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    if time.time() - start_time >= 1:\n",
    "                        dress_index = current_dress_index % len(dress_images)\n",
    "                        process_and_save_output(frame, dress_index, detections, x, y, w, h)\n",
    "                        current_dress_index += 1\n",
    "\n",
    "                        if current_dress_index >= len(dress_images):\n",
    "                            processed_all_dresses = True\n",
    "                            break\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
