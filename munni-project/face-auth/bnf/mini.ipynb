{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: .\\assets\\shirt11.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#base -- original\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "### idhi github la kelli eskochina already pre-trained model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "current_dress_index = 0\n",
    "user_picture_path = r'.\\assets'\n",
    "\n",
    "################################ kindha code gpt la kelli eskochindhi ###################################\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        #print('Selected shirt image:', image_path) #idhi anvasaram ga print chesthandhi errors appudu enable cheskundham\n",
    "\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "def process_dress_image(img): ## dheeni baadha endho kuda ardham aiethaledh, okka transparency osthey aiepothadhi ga saava dobbhuthandhi\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            # Split channels\n",
    "            b, g, r = cv2.split(img)\n",
    "            \n",
    "            # Create alpha channel (fully opaque)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            \n",
    "            # Merge channels to form RGBA image\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            \n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "################################ paina code gpt la kelli eskochindhi but waste ###################################\n",
    "\n",
    "def apply_shirt(frame, dress_index, detections):\n",
    "    global dress_images\n",
    "    if dress_images and dress_index < len(dress_images):\n",
    "        confidence_threshold = 0.5  \n",
    "        detected_faces = []\n",
    "        \n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            \n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                detected_faces.append((x, y, w, h))\n",
    "\n",
    "        if detected_faces:\n",
    "            dress_img = dress_images[dress_index]\n",
    "            aspect_ratio = dress_img.shape[1] / dress_img.shape[0]\n",
    "\n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                y_shirt = y + int(0.8 * h)\n",
    "                h_shirt = int(0.5 * h)\n",
    "                x_offset = int(0.5 * w)\n",
    "                x_shirt = max(x - x_offset, 0)\n",
    "                w_shirt = min(w + 2 * x_offset, frame.shape[1] - x_shirt)\n",
    "                new_h_shirt = int(w_shirt / aspect_ratio)\n",
    "\n",
    "                if new_h_shirt > 0:\n",
    "                    resized_shirt = cv2.resize(dress_img, (w_shirt, new_h_shirt), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                    if resized_shirt.shape[2] == 4:\n",
    "                        resized_shirt = resized_shirt[:, :, :3]\n",
    "\n",
    "                    frame[y_shirt:y_shirt + new_h_shirt, x_shirt:x_shirt + w_shirt] = resized_shirt[\n",
    "                                                                                        :min(new_h_shirt,\n",
    "                                                                                             frame.shape[0] - y_shirt),\n",
    "                                                                                        :min(w_shirt,\n",
    "                                                                                             frame.shape[1] - x_shirt)]\n",
    "                    \n",
    "##########################   ee paina code gpt improvise chesindhi changes em cheyyodhu malla pisukuthadhi   ##########################\n",
    "                    \n",
    "def process_and_save_output(frame, dress_index, detections):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        apply_shirt(frame_copy, dress_index, detections)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    global current_dress_index\n",
    "\n",
    "    start_time = time.time()\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        apply_shirt(frame, current_dress_index, detections)\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        elif key == 13:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "        \n",
    "        if time.time() - start_time >= 1:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "            start_time = time.time()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base -- transparency\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Load dress images with alpha channel\n",
    "def load_dress_images(folder_path):\n",
    "    dress_images = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            dress_images.append(img)\n",
    "        else:\n",
    "            print(f'Error loading image: {file_path}')\n",
    "    return dress_images\n",
    "\n",
    "# Overlay dress on detected faces\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(0.8 * h)\n",
    "    dress_x = x + int((w - resized_dress.shape[1]) / 2)\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Folder path containing dress images\n",
    "    dress_folder_path = r'.\\assets'\n",
    "\n",
    "    # Load dress images\n",
    "    dress_images = load_dress_images(dress_folder_path)\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## producing final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output0.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 151\u001b[0m\n\u001b[0;32m    148\u001b[0m     cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 151\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 133\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m             dress_img \u001b[38;5;241m=\u001b[39m dress_images[dress_index]\n\u001b[0;32m    131\u001b[0m             apply_dress(frame, dress_img, x, y, w, h)\n\u001b[1;32m--> 133\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#this is only saving one\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Load dress images with alpha channel\n",
    "def load_dress_images(folder_path):\n",
    "    dress_images = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            dress_images.append(img)\n",
    "        else:\n",
    "            print(f'Error loading image: {file_path}')\n",
    "    return dress_images\n",
    "\n",
    "# Overlay dress on detected faces\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(0.8 * h)\n",
    "    dress_x = x + int((w - resized_dress.shape[1]) / 2)\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "#saving\n",
    "def process_and_save_output(frame, detections, dress_index):\n",
    "    dress_index = 0\n",
    "\n",
    "    # global user_picture_path\n",
    "    # user_picture_path = 'outputls'\n",
    "    # if user_picture_path:\n",
    "    output_folder = 'outputs'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "    dress_index = dress_index + 1\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    cv2.imwrite(output_path, frame_copy)\n",
    "    print(f'Saved output image: {output_path}')\n",
    "\n",
    "        \n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Folder path containing dress images\n",
    "    dress_folder_path = r'.\\assets'\n",
    "\n",
    "    dress_index = None\n",
    "    # Load dress images\n",
    "    dress_images = load_dress_images(dress_folder_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        elif key == 13:\n",
    "            process_and_save_output(frame,  detections, dress_index)\n",
    "            # if current_dress_index == 0: \n",
    "            #     break\n",
    "        \n",
    "        if time.time() - start_time >= 1:\n",
    "            process_and_save_output(frame, detections, dress_index)\n",
    "            # if current_dress_index == 0: \n",
    "            #     break\n",
    "            # start_time = time.time()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n",
      "Saved output image: outputs\\output_dress_0_0.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 140\u001b[0m\n\u001b[0;32m    137\u001b[0m     cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 140\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 127\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    124\u001b[0m detections \u001b[38;5;241m=\u001b[39m net\u001b[38;5;241m.\u001b[39mforward()\n\u001b[0;32m    126\u001b[0m \u001b[38;5;66;03m# Process and save output images\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m \u001b[43mprocess_and_save_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdress_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "Cell \u001b[1;32mIn[4], line 98\u001b[0m, in \u001b[0;36mprocess_and_save_output\u001b[1;34m(frame, detections, dress_images)\u001b[0m\n\u001b[0;32m     96\u001b[0m dress_img \u001b[38;5;241m=\u001b[39m dress_images[dress_index]\n\u001b[0;32m     97\u001b[0m frame_with_dress \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Create a copy of the frame to avoid modifying the original frame\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m \u001b[43mapply_dress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_with_dress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdress_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# Save output image with a unique filename for each detected face\u001b[39;00m\n\u001b[0;32m    101\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_dress_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdress_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 75\u001b[0m, in \u001b[0;36mapply_dress\u001b[1;34m(frame, dress_img, x, y, w, h)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Loop through each channel (BGR) and perform element-wise operations\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m---> 75\u001b[0m     roi[:, :, c] \u001b[38;5;241m=\u001b[39m (dress_mask \u001b[38;5;241m*\u001b[39m resized_dress[:, :, c] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     76\u001b[0m                     inv_dress_mask \u001b[38;5;241m*\u001b[39m roi[:, :, c])\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Update the region of interest in the frame with the dress overlay\u001b[39;00m\n\u001b[0;32m     79\u001b[0m frame[dress_y:dress_y_end, dress_x:dress_x_end] \u001b[38;5;241m=\u001b[39m roi\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#only saving output0_0\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variable for dress index\n",
    "dress_index = 0\n",
    "\n",
    "# Load dress images with alpha channel\n",
    "def load_dress_images(folder_path):\n",
    "    dress_images = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            dress_images.append(img)\n",
    "        else:\n",
    "            print(f'Error loading image: {file_path}')\n",
    "    return dress_images\n",
    "\n",
    "# Overlay dress on detected faces\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(0.8 * h)\n",
    "    dress_x = x + int((w - resized_dress.shape[1]) / 2)\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "# Saving images with dress overlays\n",
    "def process_and_save_output(frame, detections, dress_images):\n",
    "    global dress_index\n",
    "    output_folder = 'outputs'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:  # Confidence threshold\n",
    "            # Get face coordinates\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (x, y, w, h) = box.astype(int)\n",
    "\n",
    "            # Apply dress on detected face\n",
    "            dress_index = i % len(dress_images)\n",
    "            dress_img = dress_images[dress_index]\n",
    "            frame_with_dress = frame.copy()  # Create a copy of the frame to avoid modifying the original frame\n",
    "            apply_dress(frame_with_dress, dress_img, x, y, w, h)\n",
    "\n",
    "            # Save output image with a unique filename for each detected face\n",
    "            output_path = os.path.join(output_folder, f'output_dress_{dress_index}_{i}.png')\n",
    "            cv2.imwrite(output_path, frame_with_dress)\n",
    "            print(f'Saved output image: {output_path}')\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Folder path containing dress images\n",
    "    dress_folder_path = r'.\\assets'\n",
    "\n",
    "    # Load dress images\n",
    "    dress_images = load_dress_images(dress_folder_path)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Process and save output images\n",
    "        process_and_save_output(frame, detections, dress_images)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        \n",
    "        if time.time() - start_time >= 1:\n",
    "            start_time = time.time()  # Reset the start time\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# produc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 1\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "# Overlay dress on detected faces\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(0.8 * h)\n",
    "    dress_x = x + int((w - resized_dress.shape[1]) / 2)\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 2\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "            \n",
    "\n",
    "def process_dress_image(img): ## dheeni baadha endho kuda ardham aiethaledh, okka transparency osthey aiepothadhi ga saava dobbhuthandhi\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            # Split channels\n",
    "            b, g, r = cv2.split(img)\n",
    "            \n",
    "            # Create alpha channel (fully opaque)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            \n",
    "            # Merge channels to form RGBA image\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            \n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face and enlarge it even more\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 2.0, fy=scale_factor * 2.0)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(0.8 * h)\n",
    "\n",
    "    # Adjust the x-coordinate to move the dress more to the right\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 300  # Adjust the value as needed\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face and enlarge it even more\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 2.0, fy=scale_factor * 2.0)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(1.2 * h)\n",
    "\n",
    "    # Adjust the x-coordinate to move the dress more to the right\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 250  # Adjust the value as needed\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Get the region of interest in the frame for the dress overlay\n",
    "    roi = frame[dress_y:dress_y_end, dress_x:dress_x_end]\n",
    "\n",
    "    # Resize the dress mask to match the size of the ROI\n",
    "    resized_dress_mask = cv2.resize(dress_img[:, :, 3], (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Create a mask for the dress overlay\n",
    "    dress_mask = resized_dress_mask / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Ensure the dress and ROI have the same shape\n",
    "    if resized_dress.shape[:2] != roi.shape[:2]:\n",
    "        resized_dress = cv2.resize(resized_dress, (roi.shape[1], roi.shape[0]))\n",
    "\n",
    "    # Loop through each channel (BGR) and perform element-wise operations\n",
    "    for c in range(0, 3):\n",
    "        roi[:, :, c] = (dress_mask * resized_dress[:, :, c] +\n",
    "                        inv_dress_mask * roi[:, :, c])\n",
    "\n",
    "    # Update the region of interest in the frame with the dress overlay\n",
    "    frame[dress_y:dress_y_end, dress_x:dress_x_end] = roi\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# here is important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3.0 #left over will not be shown in camera\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face and enlarge it slightly\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 2.5, fy=scale_factor * 2.5)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(h * 0.8)  # Adjust the value to position the dress below the neck\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 270\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest for the dress overlay\n",
    "    dress_roi_y_start = max(dress_y, 0)\n",
    "    dress_roi_y_end = min(dress_y_end, frame.shape[0])\n",
    "    dress_roi_x_start = max(dress_x, 0)\n",
    "    dress_roi_x_end = min(dress_x_end, frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest in the dress image\n",
    "    dress_img_roi_y_start = dress_roi_y_start - dress_y\n",
    "    dress_img_roi_y_end = dress_img_roi_y_start + (dress_roi_y_end - dress_roi_y_start)\n",
    "    dress_img_roi_x_start = dress_roi_x_start - dress_x\n",
    "    dress_img_roi_x_end = dress_img_roi_x_start + (dress_roi_x_end - dress_roi_x_start)\n",
    "\n",
    "    # Extract the dress overlay and mask within the region of interest\n",
    "    dress_overlay = resized_dress[dress_img_roi_y_start:dress_img_roi_y_end, dress_img_roi_x_start:dress_img_roi_x_end]\n",
    "    dress_mask = dress_overlay[:, :, 3] / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Apply the dress overlay to the frame within the region of interest\n",
    "    frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3] = (\n",
    "            dress_mask[:, :, np.newaxis] * dress_overlay[:, :, :3] +\n",
    "            inv_dress_mask[:, :, np.newaxis] * frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = i % len(dress_images)\n",
    "                    dress_img = dress_images[dress_index]\n",
    "                    apply_dress(frame, dress_img, x, y, w, h)\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3.1 #left over will not be shown in camera and also the total transparent\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face and enlarge it slightly\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 2.5, fy=scale_factor * 2.5)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(h * 0.8)  # Adjust the value to position the dress below the neck\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 250\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest for the dress overlay\n",
    "    dress_roi_y_start = max(dress_y, 0)\n",
    "    dress_roi_y_end = min(dress_y_end, frame.shape[0])\n",
    "    dress_roi_x_start = max(dress_x, 0)\n",
    "    dress_roi_x_end = min(dress_x_end, frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest in the dress image\n",
    "    dress_img_roi_y_start = dress_roi_y_start - dress_y\n",
    "    dress_img_roi_y_end = dress_img_roi_y_start + (dress_roi_y_end - dress_roi_y_start)\n",
    "    dress_img_roi_x_start = dress_roi_x_start - dress_x\n",
    "    dress_img_roi_x_end = dress_img_roi_x_start + (dress_roi_x_end - dress_roi_x_start)\n",
    "\n",
    "    # Extract the dress overlay and mask within the region of interest\n",
    "    dress_overlay = resized_dress[dress_img_roi_y_start:dress_img_roi_y_end, dress_img_roi_x_start:dress_img_roi_x_end]\n",
    "    dress_mask = dress_overlay[:, :, -1] / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Apply the dress overlay to the frame within the region of interest\n",
    "    frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3] = (\n",
    "            dress_mask[:, :, np.newaxis] * dress_overlay[:, :, :3] +\n",
    "            inv_dress_mask[:, :, np.newaxis] * frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3]\n",
    "    )\n",
    "\n",
    "def process_and_save_output(frame, dress_index, detections, x, y, w, h):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        dress_img = dress_images[dress_index]\n",
    "        apply_dress(frame_copy, dress_img, x, y, w, h)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "    \n",
    "    current_dress_index = 0\n",
    "    processed_all_dresses = False\n",
    "\n",
    "    while cam.isOpened() and not processed_all_dresses:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    dress_index = current_dress_index % len(dress_images)\n",
    "                    process_and_save_output(frame, dress_index, detections, x, y, w, h)\n",
    "                    current_dress_index += 1\n",
    "\n",
    "                    if current_dress_index >= len(dress_images):\n",
    "                        processed_all_dresses = True\n",
    "                        break\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3.2 #left over will not be shown in camera and also the total transparent\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the minimum scale factor to ensure the dress fits within the detected face\n",
    "    scale_factor = min(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face and enlarge it slightly\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 2.5, fy=scale_factor * 2.5)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(h * 0.8)  # Adjust the value to position the dress below the neck\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 250\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest for the dress overlay\n",
    "    dress_roi_y_start = max(dress_y, 0)\n",
    "    dress_roi_y_end = min(dress_y_end, frame.shape[0])\n",
    "    dress_roi_x_start = max(dress_x, 0)\n",
    "    dress_roi_x_end = min(dress_x_end, frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest in the dress image\n",
    "    dress_img_roi_y_start = dress_roi_y_start - dress_y\n",
    "    dress_img_roi_y_end = dress_img_roi_y_start + (dress_roi_y_end - dress_roi_y_start)\n",
    "    dress_img_roi_x_start = dress_roi_x_start - dress_x\n",
    "    dress_img_roi_x_end = dress_img_roi_x_start + (dress_roi_x_end - dress_roi_x_start)\n",
    "\n",
    "    # Extract the dress overlay and mask within the region of interest\n",
    "    dress_overlay = resized_dress[dress_img_roi_y_start:dress_img_roi_y_end, dress_img_roi_x_start:dress_img_roi_x_end]\n",
    "    dress_mask = dress_overlay[:, :, -1] / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Apply the dress overlay to the frame within the region of interest\n",
    "    frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3] = (\n",
    "            dress_mask[:, :, np.newaxis] * dress_overlay[:, :, :3] +\n",
    "            inv_dress_mask[:, :, np.newaxis] * frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3]\n",
    "    )\n",
    "\n",
    "def process_and_save_output(frame, dress_index, detections, x, y, w, h):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        dress_img = dress_images[dress_index]\n",
    "        apply_dress(frame_copy, dress_img, x, y, w, h)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    current_dress_index = 0\n",
    "    processed_all_dresses = False\n",
    "\n",
    "    while cam.isOpened() and not processed_all_dresses:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    if time.time() - start_time >= 1:\n",
    "                        dress_index = current_dress_index % len(dress_images)\n",
    "                        process_and_save_output(frame, dress_index, detections, x, y, w, h)\n",
    "                        current_dress_index += 1\n",
    "\n",
    "                        if current_dress_index >= len(dress_images):\n",
    "                            processed_all_dresses = True\n",
    "                            break\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\assets\\shirt0.png\n",
      ".\\assets\\shirt1.png\n",
      ".\\assets\\shirt2.png\n",
      ".\\assets\\shirt3.png\n",
      ".\\assets\\shirt4.png\n",
      ".\\assets\\shirt5.png\n",
      ".\\assets\\shirt6.png\n",
      ".\\assets\\shirt7.png\n",
      ".\\assets\\shirt8.png\n",
      ".\\assets\\shirt9.png\n",
      ".\\assets\\shirt10.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#check  point 3.3 #left over will not be shown in camera and also the total transparent\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "# Global variables\n",
    "dress_images = []\n",
    "\n",
    "user_picture_path = r'.\\assets'\n",
    "total_dresses = 11\n",
    "# Load dress images\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(total_dresses):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        print(image_path)\n",
    "        dress_images.append(img)\n",
    "\n",
    "def apply_dress(frame, dress_img, x, y, w, h):\n",
    "    dress_h, dress_w = dress_img.shape[:2]\n",
    "\n",
    "    # Calculate the scale factors for resizing the dress\n",
    "    scale_factor_x = w / dress_w\n",
    "    scale_factor_y = h / dress_h\n",
    "\n",
    "    # Take the maximum scale factor to enlarge the dress as much as possible while fitting within the detected face\n",
    "    scale_factor = max(scale_factor_x, scale_factor_y)\n",
    "\n",
    "    # Resize the dress image to fit the detected face\n",
    "    resized_dress = cv2.resize(dress_img, None, fx=scale_factor * 1.5, fy=scale_factor * 1.5)\n",
    "\n",
    "    # Calculate the coordinates for the dress overlay\n",
    "    dress_y = y + int(h * 0.8)  # Adjust the value to position the dress below the neck\n",
    "    dress_x = x - int((resized_dress.shape[1] - w) / 2) - 200\n",
    "\n",
    "    # Ensure dress overlay does not go out of bounds\n",
    "    dress_y_end = min(dress_y + resized_dress.shape[0], frame.shape[0])\n",
    "    dress_x_end = min(dress_x + resized_dress.shape[1], frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest for the dress overlay\n",
    "    dress_roi_y_start = max(dress_y, 0)\n",
    "    dress_roi_y_end = min(dress_y_end, frame.shape[0])\n",
    "    dress_roi_x_start = max(dress_x, 0)\n",
    "    dress_roi_x_end = min(dress_x_end, frame.shape[1])\n",
    "\n",
    "    # Calculate the region of interest in the dress image\n",
    "    dress_img_roi_y_start = dress_roi_y_start - dress_y\n",
    "    dress_img_roi_y_end = dress_img_roi_y_start + (dress_roi_y_end - dress_roi_y_start)\n",
    "    dress_img_roi_x_start = dress_roi_x_start - dress_x\n",
    "    dress_img_roi_x_end = dress_img_roi_x_start + (dress_roi_x_end - dress_roi_x_start)\n",
    "\n",
    "    # Extract the dress overlay and mask within the region of interest\n",
    "    dress_overlay = resized_dress[dress_img_roi_y_start:dress_img_roi_y_end, dress_img_roi_x_start:dress_img_roi_x_end]\n",
    "    dress_mask = dress_overlay[:, :, -1] / 255.0\n",
    "\n",
    "    # Invert the dress mask\n",
    "    inv_dress_mask = 1.0 - dress_mask\n",
    "\n",
    "    # Apply the dress overlay to the frame within the region of interest\n",
    "    frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3] = (\n",
    "            dress_mask[:, :, np.newaxis] * dress_overlay[:, :, :3] +\n",
    "            inv_dress_mask[:, :, np.newaxis] * frame[dress_roi_y_start:dress_roi_y_end, dress_roi_x_start:dress_roi_x_end, :3]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def process_and_save_output(frame, dress_index, detections, x, y, w, h):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        dress_img = dress_images[dress_index]\n",
    "        apply_dress(frame_copy, dress_img, x, y, w, h)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "def main():\n",
    "    # Select dress images\n",
    "    select_dress_images()\n",
    "    \n",
    "    start_time = time.time()\n",
    "    current_dress_index = 0\n",
    "    processed_all_dresses = False\n",
    "\n",
    "    while cam.isOpened() and not processed_all_dresses:\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        # Convert frame to blob for face detection\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        # Iterate through detections\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.5:  # Confidence threshold\n",
    "                # Get face coordinates\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                # Apply dress on detected face\n",
    "                if dress_images:\n",
    "                    if time.time() - start_time >= 1:\n",
    "                        dress_index = current_dress_index % len(dress_images)\n",
    "                        process_and_save_output(frame, dress_index, detections, x, y, w, h)\n",
    "                        current_dress_index += 1\n",
    "\n",
    "                        if current_dress_index >= len(dress_images):\n",
    "                            processed_all_dresses = True\n",
    "                            break\n",
    "\n",
    "        # Display frame with dress overlay\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
