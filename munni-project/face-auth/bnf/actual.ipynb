{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# asal code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: .\\assets\\shirt11.png\n",
      "Saved output image: outputs\\output0.png\n",
      "Saved output image: outputs\\output1.png\n",
      "Saved output image: outputs\\output2.png\n",
      "Saved output image: outputs\\output3.png\n",
      "Saved output image: outputs\\output4.png\n",
      "Saved output image: outputs\\output5.png\n",
      "Saved output image: outputs\\output6.png\n",
      "Saved output image: outputs\\output7.png\n",
      "Saved output image: outputs\\output8.png\n",
      "Saved output image: outputs\\output9.png\n",
      "Saved output image: outputs\\output10.png\n"
     ]
    }
   ],
   "source": [
    "#date : 1.4.24\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "### idhi github la kelli eskochina already pre-trained model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "current_dress_index = 0\n",
    "user_picture_path = r'.\\assets'\n",
    "\n",
    "################################ kindha code gpt la kelli eskochindhi ###################################\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        #print('Selected shirt image:', image_path) #idhi anvasaram ga print chesthandhi errors appudu enable cheskundham\n",
    "\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "def process_dress_image(img): ## dheeni baadha endho kuda ardham aiethaledh, okka transparency osthey aiepothadhi ga saava dobbhuthandhi\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            # Split channels\n",
    "            b, g, r = cv2.split(img)\n",
    "            \n",
    "            # Create alpha channel (fully opaque)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            \n",
    "            # Merge channels to form RGBA image\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            \n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "    \n",
    "################################ paina code gpt la kelli eskochindhi but waste ###################################\n",
    "\n",
    "def apply_shirt(frame, dress_index, detections):\n",
    "    global dress_images\n",
    "    if dress_images and dress_index < len(dress_images):\n",
    "        confidence_threshold = 0.5  \n",
    "        detected_faces = []\n",
    "        \n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            \n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                \n",
    "                detected_faces.append((x, y, w, h))\n",
    "\n",
    "        if detected_faces:\n",
    "            dress_img = dress_images[dress_index]\n",
    "            aspect_ratio = dress_img.shape[1] / dress_img.shape[0]\n",
    "\n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                y_shirt = y + int(0.8 * h)\n",
    "                h_shirt = int(0.5 * h)\n",
    "                x_offset = int(0.5 * w)\n",
    "                x_shirt = max(x - x_offset, 0)\n",
    "                w_shirt = min(w + 2 * x_offset, frame.shape[1] - x_shirt)\n",
    "                new_h_shirt = int(w_shirt / aspect_ratio)\n",
    "\n",
    "                if new_h_shirt > 0:\n",
    "                    resized_shirt = cv2.resize(dress_img, (w_shirt, new_h_shirt), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                    if resized_shirt.shape[2] == 4:\n",
    "                        resized_shirt = resized_shirt[:, :, :3]\n",
    "\n",
    "                    frame[y_shirt:y_shirt + new_h_shirt, x_shirt:x_shirt + w_shirt] = resized_shirt[\n",
    "                                                                                        :min(new_h_shirt,\n",
    "                                                                                             frame.shape[0] - y_shirt),\n",
    "                                                                                        :min(w_shirt,\n",
    "                                                                                             frame.shape[1] - x_shirt)]\n",
    "                    \n",
    "##########################   ee paina code gpt improvise chesindhi changes em cheyyodhu malla pisukuthadhi   ##########################\n",
    "                    \n",
    "def process_and_save_output(frame, dress_index, detections):\n",
    "    global user_picture_path\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        apply_shirt(frame_copy, dress_index, detections)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    global current_dress_index\n",
    "\n",
    "    start_time = time.time()\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        apply_shirt(frame, current_dress_index, detections)\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        elif key == 13:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "        \n",
    "        if time.time() - start_time >= 1:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "            start_time = time.time()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# idhi endhuko kuda telvadhi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt ichina background removal codes but dheniki pani raadh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for removing the background of a picture \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "shirts = []\n",
    "for i in range(7):\n",
    "    im = f'.\\\\assets\\\\shirt{i}.jpg'\n",
    "    shirts.append(im)\n",
    "    img = cv2.imread(im)\n",
    "    hh, ww = img.shape[:2]\n",
    "\n",
    "    # threshold on white\n",
    "    # Define lower and uppper limits\n",
    "    lower = np.array([200, 200, 200])\n",
    "    upper = np.array([255, 255, 255])\n",
    "\n",
    "    # Create mask to only select white\n",
    "    thresh = cv2.inRange(img, lower, upper)\n",
    "\n",
    "    # apply morphology\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (20, 20))\n",
    "    morph = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # invert morph image\n",
    "    mask = 255 - morph\n",
    "\n",
    "    # apply mask to image\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    # save results for each shirt\n",
    "    cv2.imwrite(fr'.\\assets\\shirt{i}.jpg', result)\n",
    "\n",
    "# save results\n",
    "    '''\n",
    "    cv2.imwrite('pills_thresh.jpg', thresh)\n",
    "    cv2.imwrite('pills_morph.jpg', morph)\n",
    "    cv2.imwrite('pills_mask.jpg', mask)'''\n",
    "\n",
    "    # cv2.imwrite(im, result)\n",
    "\n",
    "    # cv2.imshow('thresh', thresh)\n",
    "    # cv2.imshow('morph', morph)\n",
    "    # cv2.imshow('mask', mask)\n",
    "    # cv2.imshow('result', result)\n",
    "\n",
    "    # cv2.imshow(f'.\\assets\\shirt{i}', result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to make the image tranparent\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "im = r'.\\assets\\shirt1.jpg'\n",
    "mi = r'image_bgra.png'\n",
    "\n",
    "# read the image\n",
    "image_bgr = cv2.imread(im)\n",
    "# get the image dimensions (height, width and channels)\n",
    "h, w, c = image_bgr.shape\n",
    "# append Alpha channel -- required for BGRA (Blue, Green, Red, Alpha)\n",
    "image_bgra = np.concatenate([image_bgr, np.full((h, w, 1), 255, dtype=np.uint8)], axis=-1)\n",
    "# create a mask where white pixels ([255, 255, 255]) are True\n",
    "white = np.all(image_bgr == [255, 255, 255], axis=-1)\n",
    "# change the values of Alpha to 0 for all the white pixels\n",
    "image_bgra[white, -1] = 0\n",
    "# save the image\n",
    "\n",
    "cv2.imwrite(mi, image_bgra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def process_dress_image(img):\n",
    "    try:\n",
    "        # Check if the image has an alpha channel\n",
    "        if img.shape[2] == 4:\n",
    "            return img\n",
    "        else:\n",
    "            # Convert black pixels to transparent\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.where((b == 0) & (g == 0) & (r == 0), 0, 255).astype(np.uint8)\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(8):  # Assuming you have 8 shirt images\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        print('Selected shirt image:', image_path)\n",
    "\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "# Example usage\n",
    "dress_images = []\n",
    "user_picture_path = './assets'\n",
    "select_dress_images()\n",
    "print('Number of shirt images processed:', len(dress_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no use black to transparent\n",
    "# Import the library OpenCV \n",
    "import cv2 \n",
    "\n",
    "# Import the image \n",
    "file_name = r\".\\assets\\shirt3.png\"\n",
    "\n",
    "# Read the image \n",
    "src = cv2.imread(file_name, 1) \n",
    "\n",
    "# Convert image to image gray \n",
    "tmp = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# Applying thresholding technique \n",
    "_, alpha = cv2.threshold(tmp, 0, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "# Using cv2.split() to split channels \n",
    "# of coloured image \n",
    "b, g, r = cv2.split(src) \n",
    "\n",
    "# Making list of Red, Green, Blue \n",
    "# Channels and alpha \n",
    "rgba = [b, g, r, alpha] \n",
    "\n",
    "# Using cv2.merge() to merge rgba \n",
    "# into a coloured/multi-channeled image \n",
    "dst = cv2.merge(rgba, 4) \n",
    "\n",
    "# Writing and saving to a new image \n",
    "cv2.imwrite(\"gfg_white.png\", dst) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(r\".\\assets\\shirt1.png\")\n",
    "cv2.imshow('Original Image', image)\n",
    "\n",
    "# Create a mask initialized with zeros\n",
    "mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "# Initialize background and foreground models\n",
    "bgdModel = np.zeros((1, 65), dtype=np.float64)\n",
    "fgdModel = np.zeros((1, 65), dtype=np.float64)\n",
    "\n",
    "# Define rectangle coordinates (x, y, width, height)\n",
    "rect = (50, 30, 100, 200)\n",
    "\n",
    "# Apply GrabCut algorithm\n",
    "cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# Modify mask to create a binary mask (0: background, 1: foreground)\n",
    "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "# Create a new blank image with the same dimensions as the input image\n",
    "result = np.zeros_like(image)\n",
    "\n",
    "# Copy the segmented foreground into the new image\n",
    "result[mask2 == 1] = image[mask2 == 1]\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load source image\n",
    "source_img = cv2.imread('result_image.png')\n",
    "source_img = cv2.resize(source_img, (400, 300))  # Resize for display (optional)\n",
    "cv2.imshow('Source Image', source_img)\n",
    "\n",
    "# Convert source image to grayscale\n",
    "gray_img = cv2.cvtColor(source_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply thresholding to create a binary mask\n",
    "_, mask = cv2.threshold(gray_img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Mask', mask)\n",
    "\n",
    "# Apply the mask to the source image\n",
    "result_img = cv2.bitwise_and(source_img, source_img, mask=mask)\n",
    "cv2.imshow('Result without Transparent Background', result_img)\n",
    "\n",
    "# Create a blank white image (background)\n",
    "background = np.full_like(source_img, (255, 255, 255))\n",
    "\n",
    "# Apply the inverse mask to the background\n",
    "masked_background = cv2.bitwise_and(background, background, mask=cv2.bitwise_not(mask))\n",
    "\n",
    "# Combine the masked background and the result image\n",
    "result_with_mask = cv2.add(masked_background, result_img)\n",
    "cv2.imshow('Result with Mask', result_with_mask)\n",
    "\n",
    "# Add transparency (alpha channel) to the final result\n",
    "rgba_result = cv2.cvtColor(result_with_mask, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "# Set alpha channel values based on the mask\n",
    "rgba_result[:, :, 3] = mask\n",
    "\n",
    "cv2.imshow('Result with Transparent Background', rgba_result)\n",
    "cv2.imwrite(\"a.png\",rgba_result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from github code\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('reseul_image.png')\n",
    "overlay_t = cv2.imread('foreground_transparent.png',-1) # -1 loads with transparency\n",
    "\n",
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "\t\"\"\"\n",
    "\t@brief      Overlays a transparant PNG onto another image using CV2\n",
    "\t\n",
    "\t@param      background_img    The background image\n",
    "\t@param      img_to_overlay_t  The transparent image to overlay (has alpha channel)\n",
    "\t@param      x                 x location to place the top-left corner of our overlay\n",
    "\t@param      y                 y location to place the top-left corner of our overlay\n",
    "\t@param      overlay_size      The size to scale our overlay to (tuple), no scaling if None\n",
    "\t\n",
    "\t@return     Background image with overlay on top\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tbg_img = background_img.copy()\n",
    "\t\n",
    "\tif overlay_size is not None:\n",
    "\t\timg_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "\t# Extract the alpha mask of the RGBA image, convert to RGB \n",
    "\tb,g,r,a = cv2.split(img_to_overlay_t)\n",
    "\toverlay_color = cv2.merge((b,g,r))\n",
    "\t\n",
    "\t# Apply some simple filtering to remove edge noise\n",
    "\tmask = cv2.medianBlur(a,5)\n",
    "\n",
    "\th, w, _ = overlay_color.shape\n",
    "\troi = bg_img[y:y+h, x:x+w]\n",
    "\n",
    "\t# Black-out the area behind the logo in our original ROI\n",
    "\timg1_bg = cv2.bitwise_and(roi.copy(),roi.copy(),mask = cv2.bitwise_not(mask))\n",
    "\t\n",
    "\t# Mask out the logo from the logo image.\n",
    "\timg2_fg = cv2.bitwise_and(overlay_color,overlay_color,mask = mask)\n",
    "\n",
    "\t# Update the original image with our new ROI\n",
    "\tbg_img[y:y+h, x:x+w] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "\treturn bg_img\n",
    "\n",
    "cv2.imshow('image',overlay_transparent(img, overlay_t, 0, 0, (200,200)))\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i acutally need this below code for future\n",
    "### this is the best code but runs very laggy and might make exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### manam chesina code but chatgpt tkinter thoni upgradations ichindhi\n",
    "#date : 29.3.24\n",
    "\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "for i in range(6):\n",
    "    image_path = os.path.join(user_picture_path, f'shirt{i}.jpg')\n",
    "    print('Selected shirt images:', image_path)\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is not None:\n",
    "        alpha_channel = np.ones((img.shape[0], img.shape[1], 1), dtype=np.uint8) * 255\n",
    "        dress_images.append(np.concatenate((img, alpha_channel), axis=2))\n",
    "    else:\n",
    "        print(f'Error loading image: {image_path}')\n",
    "\n",
    "\n",
    "current_dress_index = 0\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Virtual Try-On App\")\n",
    "\n",
    "\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "\n",
    "def update_video_feed():\n",
    "    ret, frame = cam.read()\n",
    "    if ret:\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame)\n",
    "        photo = ImageTk.PhotoImage(image=image)\n",
    "        video_label.config(image=photo)\n",
    "        video_label.image = photo\n",
    "    video_label.after(10, update_video_feed)\n",
    "\n",
    "\n",
    "def apply_shirt(frame, dress_index):\n",
    "    global dress_images\n",
    "    if dress_images and dress_index < len(dress_images):\n",
    "        detections = detect_faces(frame)\n",
    "        if detections is not None:\n",
    "            confidence_threshold = 0.5\n",
    "            detected_faces = []\n",
    "            for i in range(detections.shape[2]):\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                if confidence > confidence_threshold:\n",
    "                    box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                    (x, y, w, h) = box.astype(int)\n",
    "                    detected_faces.append((x, y, w, h))\n",
    "\n",
    "            if detected_faces:\n",
    "                dress_img = dress_images[dress_index]\n",
    "                aspect_ratio = dress_img.shape[1] / dress_img.shape[0]\n",
    "\n",
    "                for (x, y, w, h) in detected_faces:\n",
    "                    y_shirt = y + int(0.8 * h)\n",
    "                    h_shirt = int(0.5 * h)\n",
    "                    x_offset = int(0.5 * w)\n",
    "                    x_shirt = max(x - x_offset, 0)\n",
    "                    w_shirt = min(w + 2 * x_offset, frame.shape[1] - x_shirt)\n",
    "                    new_h_shirt = int(w_shirt / aspect_ratio)\n",
    "\n",
    "                    if new_h_shirt > 0:\n",
    "                        resized_shirt = cv2.resize(dress_img, (w_shirt, new_h_shirt))\n",
    "                        alpha_mask = resized_shirt[:, :, 3] / 255.0\n",
    "                        alpha_mask = np.expand_dims(alpha_mask, axis=2)\n",
    "                        resized_shirt = resized_shirt[:, :, :3]\n",
    "                        frame_roi = frame[y_shirt:y_shirt + new_h_shirt, x_shirt:x_shirt + w_shirt]\n",
    "                        frame_roi = cv2.addWeighted(frame_roi, 1.0, resized_shirt, 0.5, 0)\n",
    "                        frame[y_shirt:y_shirt + new_h_shirt, x_shirt:x_shirt + w_shirt] = frame_roi\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "def detect_faces(frame):\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    return net.forward()\n",
    "\n",
    "def process_and_save_output(frame, dress_index):\n",
    "    global start_time, current_dress_index\n",
    "    output_folder = 'outputs'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    output_path = os.path.join(output_folder, f'output{dress_index}.png')\n",
    "    frame_copy = frame.copy()\n",
    "    result_frame = apply_shirt(frame_copy, dress_index)\n",
    "    cv2.imwrite(output_path, result_frame)\n",
    "    print(f'Saved output image: {output_path}')\n",
    "    current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "start_button = tk.Button(root, text=\"Start Try-On\", command=lambda: process_and_save_output(cam.read()[1], current_dress_index))\n",
    "start_button.pack()\n",
    "\n",
    "\n",
    "def update_and_try_on():\n",
    "    update_video_feed()\n",
    "    if time.time() - start_time >= 5:\n",
    "        process_and_save_output(cam.read()[1], current_dress_index)\n",
    "    root.after(10, update_and_try_on)\n",
    "\n",
    "update_and_try_on()\n",
    "root.mainloop()\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam.release()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
