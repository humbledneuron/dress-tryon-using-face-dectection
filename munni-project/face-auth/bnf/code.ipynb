{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the base code, transparent background is either black or white and in the end alll shirts are opened\n",
    "import cv2\n",
    "import tkinter as tk\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "current_dress_index = 0\n",
    "user_picture_path = r'.\\assets'\n",
    "output_image_paths = []\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "def process_dress_image(img):\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img\n",
    "        else:\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def apply_dress(frame, dress_index, detections):\n",
    "    global dress_images\n",
    "    if dress_images and dress_index < len(dress_images):\n",
    "        confidence_threshold = 0.5  \n",
    "        detected_faces = []\n",
    "        \n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                detected_faces.append((x, y, w, h))\n",
    "\n",
    "        if detected_faces:\n",
    "            dress_img = dress_images[dress_index]\n",
    "            aspect_ratio = dress_img.shape[1] / dress_img.shape[0]\n",
    "\n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                y_dress = y + int(0.8 * h)\n",
    "                h_dress = int(0.5 * h)\n",
    "                x_offset = int(0.5 * w)\n",
    "                x_dress = max(x - x_offset, 0)\n",
    "                w_dress = min(w + 2 * x_offset, frame.shape[1] - x_dress)\n",
    "                new_h_dress = int(w_dress / aspect_ratio)\n",
    "\n",
    "                if new_h_dress > 0:\n",
    "                    resized_dress = cv2.resize(dress_img, (w_dress, new_h_dress), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                    if resized_dress.shape[2] == 4:\n",
    "                        resized_dress = resized_dress[:, :, :3]\n",
    "\n",
    "                    frame[y_dress:y_dress + new_h_dress, x_dress:x_dress + w_dress] = resized_dress[\n",
    "                                                                                        :min(new_h_dress,\n",
    "                                                                                             frame.shape[0] - y_dress),\n",
    "                                                                                        :min(w_dress,\n",
    "                                                                                             frame.shape[1] - x_dress)]\n",
    "                    \n",
    "def process_and_save_output(frame, dress_index, detections):\n",
    "    global user_picture_path, dress_images, output_image_paths\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        apply_dress(frame_copy, dress_index, detections)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "        output_image_paths.append(output_path)\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    global current_dress_index\n",
    "\n",
    "    start_time = time.time()\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        apply_dress(frame, current_dress_index, detections)\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        elif key == 13:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "        \n",
    "        if time.time() - start_time >= 3:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "            start_time = time.time()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "    # Open all saved images\n",
    "    for image_path in output_image_paths:\n",
    "        os.system(image_path)\n",
    "        \n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above,  transparent background is either black or white and in the end alll shirts are opened\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load pre-trained face detection model\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "\n",
    "# Initialize webcam\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "# Set frame width, height, and frame rate\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "\n",
    "dress_images = []\n",
    "current_dress_index = 0\n",
    "user_picture_path = r'.\\assets'\n",
    "output_image_paths = []\n",
    "\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "\n",
    "\n",
    "def process_dress_image(img, alpha_value=255):\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.ones_like(b) * alpha_value  # Adjust alpha value here\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def apply_dress(frame, dress_index, detections):\n",
    "    global dress_images\n",
    "    if dress_images and dress_index < len(dress_images):\n",
    "        confidence_threshold = 0.5  \n",
    "        detected_faces = []\n",
    "        \n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > confidence_threshold:\n",
    "                box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "                (x, y, w, h) = box.astype(int)\n",
    "                detected_faces.append((x, y, w, h))\n",
    "\n",
    "        if detected_faces:\n",
    "            dress_img = dress_images[dress_index]\n",
    "            aspect_ratio = dress_img.shape[1] / dress_img.shape[0]\n",
    "\n",
    "            for (x, y, w, h) in detected_faces:\n",
    "                y_dress = y + int(0.8 * h)\n",
    "                h_dress = int(0.5 * h)\n",
    "                x_offset = int(0.5 * w)\n",
    "                x_dress = max(x - x_offset, 0)\n",
    "                w_dress = min(w + 2 * x_offset, frame.shape[1] - x_dress)\n",
    "                new_h_dress = int(w_dress / aspect_ratio)\n",
    "\n",
    "                if new_h_dress > 0:\n",
    "                    resized_dress = cv2.resize(dress_img, (w_dress, new_h_dress), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                    if resized_dress.shape[2] == 4:\n",
    "                        resized_dress = resized_dress[:, :, :3]\n",
    "\n",
    "                    frame[y_dress:y_dress + new_h_dress, x_dress:x_dress + w_dress] = resized_dress[\n",
    "                                                                                        :min(new_h_dress,\n",
    "                                                                                             frame.shape[0] - y_dress),\n",
    "                                                                                        :min(w_dress,\n",
    "                                                                                             frame.shape[1] - x_dress)]\n",
    "                    \n",
    "\n",
    "def process_and_save_output(frame, dress_index, detections):\n",
    "    global user_picture_path, dress_images, output_image_paths\n",
    "    if dress_images and user_picture_path:\n",
    "        output_folder = 'outputs'\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f'output{dress_index}.png')  \n",
    "        frame_copy = frame.copy()\n",
    "        apply_dress(frame_copy, dress_index, detections)\n",
    "        cv2.imwrite(output_path, frame_copy)\n",
    "        print(f'Saved output image: {output_path}')\n",
    "\n",
    "        output_image_paths.append(output_path)\n",
    "\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    global current_dress_index\n",
    "\n",
    "    time.sleep(0) #later change the digit to 5 # 5 because it gives us time settlte ourselves\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while cam.isOpened():\n",
    "        ret, frame = cam.read()\n",
    "        if not ret:\n",
    "            print('Error: Failed to open webcam or read frame')\n",
    "            break\n",
    "            \n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        \n",
    "        apply_dress(frame, current_dress_index, detections)\n",
    "        cv2.imshow('Virtual Try-On', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('.'):\n",
    "            break\n",
    "        elif key == 13: #press enter to get next shirt\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "        \n",
    "        if time.time() - start_time >= 3:\n",
    "            process_and_save_output(frame, current_dress_index, detections)\n",
    "            current_dress_index = (current_dress_index + 1) % len(dress_images)\n",
    "            if current_dress_index == 0: \n",
    "                break\n",
    "            start_time = time.time()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "    # Open all saved images in the end\n",
    "    for image_path in output_image_paths:\n",
    "        os.system(image_path)\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: .\\assets\\shirt11.png\n",
      "Saved captured image: outputs\\captured_image.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (145,400,3) (0,387,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    100\u001b[0m     cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 102\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     96\u001b[0m picture_path \u001b[38;5;241m=\u001b[39m take_and_save_picture()\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m picture_path:\n\u001b[1;32m---> 98\u001b[0m     \u001b[43mapply_dress_to_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    100\u001b[0m cam\u001b[38;5;241m.\u001b[39mrelease()\n",
      "Cell \u001b[1;32mIn[1], line 86\u001b[0m, in \u001b[0;36mapply_dress_to_picture\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     84\u001b[0m         alpha_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(alpha_mask[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Convert to 3-channel alpha mask\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         blended_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 86\u001b[0m         blended_img[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw] \u001b[38;5;241m=\u001b[39m alpha_mask \u001b[38;5;241m*\u001b[39m resized_dress[:, :, :\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     87\u001b[0m         img \u001b[38;5;241m=\u001b[39m blended_img\n\u001b[0;32m     89\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_image.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (145,400,3) (0,387,3) "
     ]
    }
   ],
   "source": [
    "#this code works as transparent but the shirt is being applied above the face\n",
    "#but working with the laptop camera \n",
    "#middle values in the error indicates our face x,y locations\n",
    "# this saves the picture and  then applies the shirts\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def process_dress_image(img):\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "    \n",
    "def take_and_save_picture():\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('Error: Failed to open webcam or read frame')\n",
    "        return None\n",
    "    output_path = os.path.join(output_folder, 'captured_image.png')\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f'Saved captured image: {output_path}')\n",
    "    return output_path\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "def apply_dress_to_picture(image_path):\n",
    "    global dress_images\n",
    "    if not dress_images:\n",
    "        print('Error: No dress images found')\n",
    "        return\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "            (x, y, w, h) = box.astype(int)\n",
    "            dress_img = dress_images[i % len(dress_images)]  # Choose a dress from the available options\n",
    "            resized_dress = cv2.resize(dress_img, (w, h))\n",
    "\n",
    "            # Perform alpha blending\n",
    "            alpha_mask = resized_dress[:, :, 3] / 255.0\n",
    "            alpha_mask = np.repeat(alpha_mask[:, :, np.newaxis], 3, axis=2)  # Convert to 3-channel alpha mask\n",
    "            blended_img = img.copy()\n",
    "            blended_img[y:y+h, x:x+w] = alpha_mask * resized_dress[:, :, :3] + (1 - alpha_mask) * img[y:y+h, x:x+w]\n",
    "            img = blended_img\n",
    "    \n",
    "    output_path = os.path.join(output_folder, 'output_image.png')\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f'Saved output image with dresses: {output_path}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    picture_path = take_and_save_picture()\n",
    "    if picture_path:\n",
    "        apply_dress_to_picture(picture_path)\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image: .\\assets\\shirt11.png\n",
      "Saved captured image: outputs\\captured_image.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (144,399,3) (144,388,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 154\u001b[0m\n\u001b[0;32m    151\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    152\u001b[0m     cam\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 154\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 150\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    148\u001b[0m picture_path \u001b[38;5;241m=\u001b[39m take_and_save_picture()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m picture_path:\n\u001b[1;32m--> 150\u001b[0m     \u001b[43mapply_dress_to_picture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpicture_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    152\u001b[0m cam\u001b[38;5;241m.\u001b[39mrelease()\n",
      "Cell \u001b[1;32mIn[2], line 138\u001b[0m, in \u001b[0;36mapply_dress_to_picture\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m    136\u001b[0m         alpha_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrepeat(alpha_mask[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis], \u001b[38;5;241m3\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Convert to 3-channel alpha mask\u001b[39;00m\n\u001b[0;32m    137\u001b[0m         blended_img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 138\u001b[0m         blended_img[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw] \u001b[38;5;241m=\u001b[39m alpha_mask \u001b[38;5;241m*\u001b[39m resized_dress[:, :, :\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    139\u001b[0m         img \u001b[38;5;241m=\u001b[39m blended_img\n\u001b[0;32m    141\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_image.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (144,399,3) (144,388,3) "
     ]
    }
   ],
   "source": [
    "#this code works as transparent but the shirt is being applied above the face\n",
    "#but working with the laptop camera \n",
    "#middle values in the error indicates our face x,y locations\n",
    "# this saves the picture and  then applies the shirts\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def process_dress_image(img):\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "    \n",
    "def take_and_save_picture():\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('Error: Failed to open webcam or read frame')\n",
    "        return None\n",
    "    output_path = os.path.join(output_folder, 'captured_image.png')\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f'Saved captured image: {output_path}')\n",
    "    return output_path\n",
    "\n",
    "#this code works as transparent but the shirt is being applied above the face\n",
    "#but working with the laptop camera \n",
    "#middle values in the error indicates our face x,y locations\n",
    "# this saves the picture and  then applies the shirts\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "prototxt_path = r'.\\computer_vision-master\\CAFFE_DNN\\deploy.prototxt'\n",
    "caffemodel_path = r'.\\computer_vision-master\\CAFFE_DNN\\res10_300x300_ssd_iter_140000.caffemodel'\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 520)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 380)\n",
    "cam.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "dress_images = []\n",
    "user_picture_path = r'.\\assets'\n",
    "output_folder = 'outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def process_dress_image(img):\n",
    "    try:\n",
    "        if img.shape[2] == 4:\n",
    "            return img  # Image already has an alpha channel\n",
    "        else:\n",
    "            b, g, r = cv2.split(img)\n",
    "            alpha = np.ones_like(b) * 255\n",
    "            rgba_img = cv2.merge((b, g, r, alpha))\n",
    "            return rgba_img\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "    \n",
    "def take_and_save_picture():\n",
    "    ret, frame = cam.read()\n",
    "    if not ret:\n",
    "        print('Error: Failed to open webcam or read frame')\n",
    "        return None\n",
    "    output_path = os.path.join(output_folder, 'captured_image.png')\n",
    "    cv2.imwrite(output_path, frame)\n",
    "    print(f'Saved captured image: {output_path}')\n",
    "    return output_path\n",
    "\n",
    "def select_dress_images():\n",
    "    global dress_images\n",
    "    dress_images.clear()\n",
    "    for i in range(12):\n",
    "        image_path = os.path.join(user_picture_path, f'shirt{i}.png')\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            processed_img = process_dress_image(img)\n",
    "            if processed_img is not None:\n",
    "                dress_images.append(processed_img)\n",
    "            else:\n",
    "                print(f'Error processing image: {image_path}')\n",
    "        else:\n",
    "            print(f'Error loading image: {image_path}')\n",
    "\n",
    "def apply_dress_to_picture(image_path):\n",
    "    global dress_images\n",
    "    if not dress_images:\n",
    "        print('Error: No dress images found')\n",
    "        return\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > 0.5:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])\n",
    "            (x, y, w, h) = box.astype(int)\n",
    "            \n",
    "            # Adjusting y-coordinate to position the dress a bit below\n",
    "            y_offset = int(0.4 * h)  # You can adjust this value as needed\n",
    "            y += y_offset\n",
    "\n",
    "            dress_img = dress_images[i % len(dress_images)]  # Choose a dress from the available options\n",
    "            resized_dress = cv2.resize(dress_img, (w, h))\n",
    "\n",
    "            # Perform alpha blending\n",
    "            alpha_mask = resized_dress[:, :, 3] / 255.0\n",
    "            alpha_mask = np.repeat(alpha_mask[:, :, np.newaxis], 3, axis=2)  # Convert to 3-channel alpha mask\n",
    "            blended_img = img.copy()\n",
    "            blended_img[y:y+h, x:x+w] = alpha_mask * resized_dress[:, :, :3] + (1 - alpha_mask) * img[y:y+h, x:x+w]\n",
    "            img = blended_img\n",
    "    \n",
    "    output_path = os.path.join(output_folder, 'output_image.png')\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f'Saved output image with dresses: {output_path}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    select_dress_images()\n",
    "    picture_path = take_and_save_picture()\n",
    "    if picture_path:\n",
    "        apply_dress_to_picture(picture_path)\n",
    "    cv2.destroyAllWindows()\n",
    "    cam.release()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
